{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WsHpVEtrqGh"
      },
      "source": [
        "Recreate paper.\n",
        "\n",
        "Source code: https://github.com/ansh941/MnistSimpleCNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp282m0fcBdq"
      },
      "source": [
        "#**EMA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vqGr-fUWXj2p"
      },
      "outputs": [],
      "source": [
        "class EMA:\n",
        "    def __init__(self, model, decay):\n",
        "        self.decay = decay\n",
        "        self.shadow = {}\n",
        "        self.original = {}\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.shadow[name] = param.data.clone()\n",
        "\n",
        "    def __call__(self, model, num_updates):\n",
        "        decay = min(self.decay, (1.0 + num_updates) / (10.0 + num_updates))\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                new_average = (1.0 - decay) * param.data + decay * self.shadow[name]\n",
        "                self.shadow[name] = new_average.clone()\n",
        "\n",
        "    def assign(self, model):\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                self.original[name] = param.data.clone()\n",
        "                param.data = self.shadow[name]\n",
        "\n",
        "    def resume(self, model):\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                param.data = self.original[name]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16_t34XjcHvf"
      },
      "source": [
        "#**Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8d0egiBncHDR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "class MnistDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, training=True, transform=None):\n",
        "        if training==True:\n",
        "            f = open('/content/drive/MyDrive/UAS ML/1 DIGIT RECOGNITION/MnistSimpleCNN-master/data/MNIST/raw/train-images-idx3-ubyte', 'rb')\n",
        "            xs = np.array(np.frombuffer(f.read(), np.uint8, offset=16))\n",
        "            f.close()\n",
        "            f = open('/content/drive/MyDrive/UAS ML/1 DIGIT RECOGNITION/MnistSimpleCNN-master/data/MNIST/raw/train-labels-idx1-ubyte', 'rb')\n",
        "            ys = np.array(np.frombuffer(f.read(), np.uint8, offset=8))\n",
        "            f.close()\n",
        "        else:\n",
        "            f = open('/content/drive/MyDrive/UAS ML/1 DIGIT RECOGNITION/MnistSimpleCNN-master/data/MNIST/raw/t10k-images-idx3-ubyte', 'rb')\n",
        "            xs = np.array(np.frombuffer(f.read(), np.uint8, offset=16))\n",
        "            f.close()\n",
        "            f = open('/content/drive/MyDrive/UAS ML/1 DIGIT RECOGNITION/MnistSimpleCNN-master/data/MNIST/raw/t10k-labels-idx1-ubyte', 'rb')\n",
        "            ys = np.array(np.frombuffer(f.read(), np.uint8, offset=8))\n",
        "            f.close()\n",
        "        xs = np.reshape(xs, (-1, 28, 28, 1)).astype(np.float32)\n",
        "        ys = ys.astype(np.int)\n",
        "        self.x_data = xs\n",
        "        self.y_data = ys\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = Image.fromarray(self.x_data[idx].reshape(28, 28))\n",
        "        y = torch.tensor(np.array(self.y_data[idx]))\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        x = transforms.ToTensor()(np.array(x)/255)\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKyKxg8fcJm5"
      },
      "source": [
        "**Transform**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YtR9AsuvcMFG"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torchvision.transforms.functional as V\n",
        "\n",
        "class RandomRotation(object):\n",
        "    def __init__(self, degrees, seed=1):\n",
        "        self.degrees = (-degrees, degrees)\n",
        "        random.seed(seed)\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_params(degrees):\n",
        "        angle = random.uniform(degrees[0], degrees[1])\n",
        "        return angle\n",
        "\n",
        "    def __call__(self, img):\n",
        "        angle = self.get_params(self.degrees)\n",
        "        return V.rotate(img, angle, False, False, None, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wq4dyudwcQW0"
      },
      "source": [
        "#**M3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "170p5IeHcQC0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelM3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelM3, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, bias=False)       # output becomes 26x26\n",
        "        self.conv1_bn = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 48, 3, bias=False)      # output becomes 24x24\n",
        "        self.conv2_bn = nn.BatchNorm2d(48)\n",
        "        self.conv3 = nn.Conv2d(48, 64, 3, bias=False)      # output becomes 22x22\n",
        "        self.conv3_bn = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 80, 3, bias=False)      # output becomes 20x20\n",
        "        self.conv4_bn = nn.BatchNorm2d(80)\n",
        "        self.conv5 = nn.Conv2d(80, 96, 3, bias=False)      # output becomes 18x18\n",
        "        self.conv5_bn = nn.BatchNorm2d(96)\n",
        "        self.conv6 = nn.Conv2d(96, 112, 3, bias=False)     # output becomes 16x16\n",
        "        self.conv6_bn = nn.BatchNorm2d(112)\n",
        "        self.conv7 = nn.Conv2d(112, 128, 3, bias=False)    # output becomes 14x14\n",
        "        self.conv7_bn = nn.BatchNorm2d(128)\n",
        "        self.conv8 = nn.Conv2d(128, 144, 3, bias=False)    # output becomes 12x12\n",
        "        self.conv8_bn = nn.BatchNorm2d(144)\n",
        "        self.conv9 = nn.Conv2d(144, 160, 3, bias=False)    # output becomes 10x10\n",
        "        self.conv9_bn = nn.BatchNorm2d(160)\n",
        "        self.conv10 = nn.Conv2d(160, 176, 3, bias=False)   # output becomes 8x8\n",
        "        self.conv10_bn = nn.BatchNorm2d(176)\n",
        "        self.fc1 = nn.Linear(11264, 10, bias=False)\n",
        "        self.fc1_bn = nn.BatchNorm1d(10)\n",
        "    def get_logits(self, x):\n",
        "        x = (x - 0.5) * 2.0\n",
        "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
        "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
        "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
        "        conv5 = F.relu(self.conv5_bn(self.conv5(conv4)))\n",
        "        conv6 = F.relu(self.conv6_bn(self.conv6(conv5)))\n",
        "        conv7 = F.relu(self.conv7_bn(self.conv7(conv6)))\n",
        "        conv8 = F.relu(self.conv8_bn(self.conv8(conv7)))\n",
        "        conv9 = F.relu(self.conv9_bn(self.conv9(conv8)))\n",
        "        conv10 = F.relu(self.conv10_bn(self.conv10(conv9)))\n",
        "        flat1 = torch.flatten(conv10.permute(0, 2, 3, 1), 1)\n",
        "        logits = self.fc1_bn(self.fc1(flat1))\n",
        "        return logits\n",
        "    def forward(self, x):\n",
        "        logits = self.get_logits(x)\n",
        "        return F.log_softmax(logits, dim=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaweIpI2cTsb"
      },
      "source": [
        "#**M5**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KIDU0MptcUl-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelM5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelM5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5, bias=False)\n",
        "        self.conv1_bn = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5, bias=False)\n",
        "        self.conv2_bn = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 96, 5, bias=False)\n",
        "        self.conv3_bn = nn.BatchNorm2d(96)\n",
        "        self.conv4 = nn.Conv2d(96, 128, 5, bias=False)\n",
        "        self.conv4_bn = nn.BatchNorm2d(128)\n",
        "        self.conv5 = nn.Conv2d(128, 160, 5, bias=False)\n",
        "        self.conv5_bn = nn.BatchNorm2d(160)\n",
        "        self.fc1 = nn.Linear(10240, 10, bias=False)\n",
        "        self.fc1_bn = nn.BatchNorm1d(10)\n",
        "    def get_logits(self, x):\n",
        "        x = (x - 0.5) * 2.0\n",
        "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
        "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
        "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
        "        conv5 = F.relu(self.conv5_bn(self.conv5(conv4)))\n",
        "        flat5 = torch.flatten(conv5.permute(0, 2, 3, 1), 1)\n",
        "        logits = self.fc1_bn(self.fc1(flat5))\n",
        "        return logits\n",
        "    def forward(self, x):\n",
        "        logits = self.get_logits(x)\n",
        "        return F.log_softmax(logits, dim=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE0BXZ1icWr9"
      },
      "source": [
        "**#M7**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "t4IAxJQEcXc8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelM7(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelM7, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 48, 7, bias=False)    # output becomes 22x22\n",
        "        self.conv1_bn = nn.BatchNorm2d(48)\n",
        "        self.conv2 = nn.Conv2d(48, 96, 7, bias=False)   # output becomes 16x16\n",
        "        self.conv2_bn = nn.BatchNorm2d(96)\n",
        "        self.conv3 = nn.Conv2d(96, 144, 7, bias=False)  # output becomes 10x10\n",
        "        self.conv3_bn = nn.BatchNorm2d(144)\n",
        "        self.conv4 = nn.Conv2d(144, 192, 7, bias=False) # output becomes 4x4\n",
        "        self.conv4_bn = nn.BatchNorm2d(192)\n",
        "        self.fc1 = nn.Linear(3072, 10, bias=False)\n",
        "        self.fc1_bn = nn.BatchNorm1d(10)\n",
        "    def get_logits(self, x):\n",
        "        x = (x - 0.5) * 2.0\n",
        "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
        "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
        "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
        "        flat1 = torch.flatten(conv4.permute(0, 2, 3, 1), 1)\n",
        "        logits = self.fc1_bn(self.fc1(flat1))\n",
        "        return logits\n",
        "    def forward(self, x):\n",
        "        logits = self.get_logits(x)\n",
        "        return F.log_softmax(logits, dim=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oftJKzIlcb5G"
      },
      "source": [
        "#**Train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxAvgc46cc0j",
        "outputId": "14247074-d4d5-4249-a38a-2b9a9fd8b195"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seeds: 0\n",
            "Epoch: 3\n",
            "Trials: 10\n",
            "Kernel size: 5\n",
            "GPU: 0\n",
            "Logdir: modelM5\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.835055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:992: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.677406\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.447411\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.381477\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.337774\n",
            "Best accuracy! correct images:  9872\n",
            "\n",
            "Test set: Average loss: 0.1571, Accuracy: 9872/10000 (98.72%) (best: 98.72%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.320439\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.243780\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.264489\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.151042\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.215020\n",
            "\n",
            "Test set: Average loss: 0.1412, Accuracy: 9835/10000 (98.35%) (best: 98.72%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.105091\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.102101\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.147225\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.156958\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.096310\n",
            "Best accuracy! correct images:  9936\n",
            "\n",
            "Test set: Average loss: 0.0507, Accuracy: 9936/10000 (99.36%) (best: 99.36%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.773786\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.620557\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.498558\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.368061\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.292252\n",
            "Best accuracy! correct images:  9888\n",
            "\n",
            "Test set: Average loss: 0.1317, Accuracy: 9888/10000 (98.88%) (best: 98.88%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.224838\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.223490\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.181320\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.224687\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.158873\n",
            "Best accuracy! correct images:  9896\n",
            "\n",
            "Test set: Average loss: 0.1095, Accuracy: 9896/10000 (98.96%) (best: 98.96%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.131590\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.128995\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.092110\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.149985\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.145483\n",
            "Best accuracy! correct images:  9928\n",
            "\n",
            "Test set: Average loss: 0.0604, Accuracy: 9928/10000 (99.28%) (best: 99.28%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.534251\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.650275\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.413561\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.390523\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.300292\n",
            "Best accuracy! correct images:  9892\n",
            "\n",
            "Test set: Average loss: 0.1370, Accuracy: 9892/10000 (98.92%) (best: 98.92%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.275691\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.157739\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.266534\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.228524\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.129822\n",
            "Best accuracy! correct images:  9922\n",
            "\n",
            "Test set: Average loss: 0.0749, Accuracy: 9922/10000 (99.22%) (best: 99.22%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.155949\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.106705\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.129960\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.105503\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.094051\n",
            "Best accuracy! correct images:  9940\n",
            "\n",
            "Test set: Average loss: 0.0487, Accuracy: 9940/10000 (99.40%) (best: 99.40%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.715487\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.606043\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.382696\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.389515\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.226230\n",
            "Best accuracy! correct images:  9894\n",
            "\n",
            "Test set: Average loss: 0.1128, Accuracy: 9894/10000 (98.94%) (best: 98.94%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.251391\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.179373\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.157792\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.117276\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.165230\n",
            "Best accuracy! correct images:  9920\n",
            "\n",
            "Test set: Average loss: 0.0708, Accuracy: 9920/10000 (99.20%) (best: 99.20%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.141526\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.171498\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.095385\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.116218\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.159260\n",
            "\n",
            "Test set: Average loss: 0.0739, Accuracy: 9891/10000 (98.91%) (best: 99.20%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.723286\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.656742\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.523788\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.307992\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.323289\n",
            "Best accuracy! correct images:  9893\n",
            "\n",
            "Test set: Average loss: 0.1406, Accuracy: 9893/10000 (98.93%) (best: 98.93%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.229264\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.215087\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.220456\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.208820\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.204050\n",
            "Best accuracy! correct images:  9904\n",
            "\n",
            "Test set: Average loss: 0.0835, Accuracy: 9904/10000 (99.04%) (best: 99.04%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.117384\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.113116\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.136924\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.135855\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.088412\n",
            "Best accuracy! correct images:  9918\n",
            "\n",
            "Test set: Average loss: 0.0598, Accuracy: 9918/10000 (99.18%) (best: 99.18%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.751878\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.701456\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.480491\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.339596\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.276727\n",
            "Best accuracy! correct images:  9881\n",
            "\n",
            "Test set: Average loss: 0.1421, Accuracy: 9881/10000 (98.81%) (best: 98.81%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.281537\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.287923\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.266595\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.160869\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.154367\n",
            "Best accuracy! correct images:  9931\n",
            "\n",
            "Test set: Average loss: 0.0677, Accuracy: 9931/10000 (99.31%) (best: 99.31%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.143998\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.198333\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.148379\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.089440\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.104282\n",
            "\n",
            "Test set: Average loss: 0.0683, Accuracy: 9923/10000 (99.23%) (best: 99.31%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.838977\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.665856\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.421854\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.426575\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.308610\n",
            "Best accuracy! correct images:  9891\n",
            "\n",
            "Test set: Average loss: 0.1408, Accuracy: 9891/10000 (98.91%) (best: 98.91%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.299349\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.264137\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.227578\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.189731\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.184406\n",
            "Best accuracy! correct images:  9912\n",
            "\n",
            "Test set: Average loss: 0.0852, Accuracy: 9912/10000 (99.12%) (best: 99.12%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.175648\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.151370\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.137332\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.123061\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.125607\n",
            "Best accuracy! correct images:  9913\n",
            "\n",
            "Test set: Average loss: 0.0733, Accuracy: 9913/10000 (99.13%) (best: 99.13%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.775707\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.627970\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.437161\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.320959\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.293800\n",
            "Best accuracy! correct images:  9881\n",
            "\n",
            "Test set: Average loss: 0.1345, Accuracy: 9881/10000 (98.81%) (best: 98.81%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.286542\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.202961\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.198243\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.233233\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.166068\n",
            "Best accuracy! correct images:  9898\n",
            "\n",
            "Test set: Average loss: 0.1013, Accuracy: 9898/10000 (98.98%) (best: 98.98%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.151682\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.144614\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.098433\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.172334\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.112966\n",
            "Best accuracy! correct images:  9908\n",
            "\n",
            "Test set: Average loss: 0.0723, Accuracy: 9908/10000 (99.08%) (best: 99.08%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.617493\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.658115\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.403755\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.383329\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.311934\n",
            "Best accuracy! correct images:  9869\n",
            "\n",
            "Test set: Average loss: 0.1324, Accuracy: 9869/10000 (98.69%) (best: 98.69%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.262236\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.276093\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.172744\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.183384\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.179537\n",
            "Best accuracy! correct images:  9910\n",
            "\n",
            "Test set: Average loss: 0.0791, Accuracy: 9910/10000 (99.10%) (best: 99.10%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.114525\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.122303\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.121192\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.146235\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.128224\n",
            "Best accuracy! correct images:  9930\n",
            "\n",
            "Test set: Average loss: 0.0529, Accuracy: 9930/10000 (99.30%) (best: 99.30%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.667550\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.565640\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.484258\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.351834\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.329755\n",
            "Best accuracy! correct images:  9899\n",
            "\n",
            "Test set: Average loss: 0.1425, Accuracy: 9899/10000 (98.99%) (best: 98.99%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.276579\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.248892\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.173601\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.166918\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.144154\n",
            "\n",
            "Test set: Average loss: 0.1191, Accuracy: 9843/10000 (98.43%) (best: 98.99%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.117645\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.131390\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.149394\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.070302\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.106467\n",
            "\n",
            "Test set: Average loss: 0.0878, Accuracy: 9865/10000 (98.65%) (best: 98.99%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# imports -------------------------------------------------------------------------#\n",
        "import sys\n",
        "import os\n",
        "import argparse\n",
        "import numpy as np \n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary\n",
        "from PIL import Image\n",
        "\n",
        "def run(p_seed=0, p_epochs=150, p_kernel_size=5, p_logdir=\"temp\"):\n",
        "    # random number generator seed ------------------------------------------------#\n",
        "    SEED = p_seed\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    np.random.seed(SEED)\n",
        "\n",
        "    # kernel size of model --------------------------------------------------------#\n",
        "    KERNEL_SIZE = p_kernel_size\n",
        "\n",
        "    # number of epochs ------------------------------------------------------------#\n",
        "    NUM_EPOCHS = p_epochs\n",
        "\n",
        "    # file names ------------------------------------------------------------------#\n",
        "    if not os.path.exists(\"/content/drive/MyDrive/UAS ML/1 DIGIT RECOGNITION/MnistSimpleCNN-master/logs/%s\"%p_logdir):\n",
        "        os.makedirs(\"/content/drive/MyDrive/UAS ML/1 DIGIT RECOGNITION/MnistSimpleCNN-master/logs/%s\"%p_logdir)\n",
        "    OUTPUT_FILE = str(\"/content/drive/MyDrive/UAS ML/1 DIGIT RECOGNITION/MnistSimpleCNN-master/logs/%s/log%03d.out\"%(p_logdir,SEED))\n",
        "    MODEL_FILE = str(\"/content/drive/MyDrive/UAS ML/1 DIGIT RECOGNITION/MnistSimpleCNN-master/logs/%s/model%03d.pth\"%(p_logdir,SEED))\n",
        "\n",
        "    # enable GPU usage ------------------------------------------------------------#\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    if use_cuda == False:\n",
        "        print(\"WARNING: CPU will be used for training.\")\n",
        "        exit(0)\n",
        "\n",
        "    # data augmentation methods ---------------------------------------------------#\n",
        "    transform = transforms.Compose([\n",
        "        RandomRotation(20, seed=SEED),\n",
        "        transforms.RandomAffine(0, translate=(0.2, 0.2)),\n",
        "        ])\n",
        "\n",
        "    # data loader -----------------------------------------------------------------#\n",
        "    train_dataset = MnistDataset(training=True, transform=transform)\n",
        "    test_dataset = MnistDataset(training=False, transform=None)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=120, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "    # model selection -------------------------------------------------------------#\n",
        "    if(KERNEL_SIZE == 3):\n",
        "        model = ModelM3().to(device)\n",
        "    elif(KERNEL_SIZE == 5):\n",
        "        model = ModelM5().to(device)\n",
        "    elif(KERNEL_SIZE == 7):\n",
        "        model = ModelM7().to(device)\n",
        "\n",
        "    summary(model, (1, 28, 28))\n",
        "\n",
        "    # hyperparameter selection ----------------------------------------------------#\n",
        "    ema = EMA(model, decay=0.999)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
        "\n",
        "    # delete result file ----------------------------------------------------------#\n",
        "    f = open(OUTPUT_FILE, 'w')\n",
        "    f.close()\n",
        "\n",
        "    # global variables ------------------------------------------------------------#\n",
        "    g_step = 0\n",
        "    max_correct = 0\n",
        "\n",
        "    # training and evaluation loop ------------------------------------------------#\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        #--------------------------------------------------------------------------#\n",
        "        # train process                                                            #\n",
        "        #--------------------------------------------------------------------------#\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_corr = 0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = F.nll_loss(output, target)\n",
        "            train_pred = output.argmax(dim=1, keepdim=True)\n",
        "            train_corr += train_pred.eq(target.view_as(train_pred)).sum().item()\n",
        "            train_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            g_step += 1\n",
        "            ema(model, g_step)\n",
        "            if batch_idx % 100 == 0:\n",
        "                print('Train Epoch: {} [{:05d}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                    100. * batch_idx / len(train_loader), loss.item()))\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_accuracy = 100 * train_corr / len(train_loader.dataset)\n",
        "\n",
        "        #--------------------------------------------------------------------------#\n",
        "        # test process                                                             #\n",
        "        #--------------------------------------------------------------------------#\n",
        "        model.eval()\n",
        "        ema.assign(model)\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        total_pred = np.zeros(0)\n",
        "        total_target = np.zeros(0)\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                total_pred = np.append(total_pred, pred.cpu().numpy())\n",
        "                total_target = np.append(total_target, target.cpu().numpy())\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            if(max_correct < correct):\n",
        "                torch.save(model.state_dict(), MODEL_FILE)\n",
        "                max_correct = correct\n",
        "                print(\"Best accuracy! correct images: %5d\"%correct)\n",
        "        ema.resume(model)\n",
        "\n",
        "        #--------------------------------------------------------------------------#\n",
        "        # output                                                                   #\n",
        "        #--------------------------------------------------------------------------#\n",
        "        test_loss /= len(test_loader.dataset)\n",
        "        test_accuracy = 100 * correct / len(test_loader.dataset)\n",
        "        best_test_accuracy = 100 * max_correct / len(test_loader.dataset)\n",
        "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%) (best: {:.2f}%)\\n'.format(\n",
        "            test_loss, correct, len(test_loader.dataset), test_accuracy, best_test_accuracy))\n",
        "\n",
        "        f = open(OUTPUT_FILE, 'a')\n",
        "        f.write(\" %3d %12.6f %9.3f %12.6f %9.3f %9.3f\\n\"%(epoch, train_loss, train_accuracy, test_loss, test_accuracy, best_test_accuracy))\n",
        "        f.close()\n",
        "\n",
        "        #--------------------------------------------------------------------------#\n",
        "        # update learning rate scheduler                                           #\n",
        "        #--------------------------------------------------------------------------#\n",
        "        lr_scheduler.step()\n",
        "\n",
        "p_seed = int(input (\"Seeds: \")) # input seeds value\n",
        "p_epoch = int(input (\"Epoch: \")) #input epoch value in each trial\n",
        "p_trials = int(input (\"Trials: \")) #input trial value\n",
        "p_kernel_size = int (input (\"Kernel size: \")) #input size kernel\n",
        "p_gpu = int(input (\"GPU: \")) #input GPU value\n",
        "p_logdir = input (\"Logdir: \") #input model\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(p_gpu)\n",
        "\n",
        "for x in range (p_trials):\n",
        "  run(p_seed + x, p_epoch, p_kernel_size, p_logdir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-d9z0TBcgWE"
      },
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "matsdZ2xchQa",
        "outputId": "baa3e3ba-d249-4f3e-c184-5ca2f052cc3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seeds: 0\n",
            "Trials: 10\n",
            "Kernel size: 5\n",
            "Logdir: modelM5\n",
            "76 [259, 435, 445, 447, 449, 582, 625, 659, 674, 740, 938, 947, 965, 1014, 1033, 1232, 1299, 1681, 1901, 2035, 2040, 2118, 2130, 2135, 2148, 2293, 2447, 2454, 2462, 2532, 2597, 2654, 3073, 3225, 3365, 3422, 3475, 3534, 3558, 3726, 3762, 3846, 4018, 4176, 4201, 4382, 4443, 4497, 4571, 4699, 4740, 4783, 4823, 4860, 5165, 5936, 5937, 5955, 6558, 6576, 6625, 6651, 6847, 8061, 8095, 8279, 8316, 8408, 8527, 9009, 9024, 9595, 9664, 9669, 9679, 9729]\n",
            "72 [445, 449, 582, 625, 716, 938, 1014, 1226, 1232, 1444, 1737, 1901, 2035, 2040, 2118, 2130, 2135, 2182, 2293, 2447, 2454, 2462, 2532, 2597, 2654, 2939, 3073, 3225, 3365, 3384, 3422, 3520, 3534, 3558, 3762, 3767, 3846, 3906, 4163, 4201, 4497, 4507, 4547, 4571, 4620, 4699, 4740, 4761, 4814, 4860, 5199, 5457, 5736, 5955, 6558, 6571, 6625, 6847, 7441, 7461, 8316, 8326, 8408, 8527, 9009, 9540, 9642, 9664, 9679, 9693, 9698, 9729]\n",
            "60 [445, 447, 449, 582, 625, 938, 947, 965, 1014, 1226, 1232, 1364, 1737, 1901, 2035, 2040, 2118, 2130, 2135, 2293, 2447, 2454, 2462, 2597, 2654, 3073, 3225, 3384, 3422, 3558, 3762, 3846, 4053, 4201, 4284, 4497, 4547, 4551, 4571, 4620, 4699, 4740, 4761, 4814, 4823, 6558, 6576, 6625, 6847, 7441, 8279, 8316, 8408, 8527, 9009, 9015, 9642, 9679, 9698, 9729]\n",
            "80 [193, 247, 447, 571, 582, 619, 659, 674, 716, 740, 956, 1112, 1226, 1242, 1299, 1393, 1403, 1527, 1621, 1737, 1754, 1901, 1911, 2035, 2040, 2118, 2130, 2148, 2182, 2266, 2447, 2462, 2488, 2582, 2597, 2907, 2939, 3073, 3132, 3225, 3288, 3533, 3534, 3558, 3726, 3846, 3906, 4201, 4382, 4740, 4783, 4860, 4911, 5159, 5842, 5888, 5936, 5937, 5955, 5972, 6576, 6625, 6783, 6883, 8061, 8275, 8279, 8316, 8325, 8387, 8408, 8527, 9009, 9015, 9071, 9729, 9749, 9754, 9792, 9922]\n",
            "82 [359, 449, 582, 625, 674, 797, 1014, 1045, 1114, 1226, 1232, 1260, 1299, 1364, 1393, 1621, 1681, 1737, 1901, 1911, 2035, 2040, 2118, 2130, 2135, 2293, 2414, 2454, 2462, 2532, 2597, 2654, 2927, 2930, 2945, 3005, 3030, 3073, 3225, 3365, 3422, 3475, 3534, 3558, 3654, 3756, 3762, 3846, 4163, 4196, 4443, 4500, 4571, 4699, 4740, 4761, 4814, 4823, 4860, 5833, 5937, 5955, 5972, 5981, 5997, 6042, 6569, 6576, 6597, 6625, 8095, 8275, 8279, 8527, 9009, 9642, 9664, 9679, 9698, 9729, 9749, 9754]\n",
            "69 [447, 449, 582, 646, 659, 740, 938, 947, 1039, 1226, 1232, 1260, 1299, 1364, 1393, 1425, 1621, 1681, 1716, 1737, 1901, 1911, 2035, 2040, 2090, 2130, 2135, 2148, 2182, 2293, 2318, 2447, 2462, 2597, 3060, 3073, 3225, 3288, 3534, 3558, 3726, 3767, 3906, 3976, 4207, 4382, 4443, 4740, 4823, 4860, 5887, 5936, 5937, 5955, 6576, 6597, 6625, 6651, 8095, 8275, 8279, 8316, 8408, 8527, 9009, 9664, 9729, 9754, 9792]\n",
            "87 [104, 193, 247, 445, 447, 582, 625, 674, 965, 1014, 1039, 1112, 1226, 1232, 1260, 1299, 1364, 1393, 1737, 1754, 1865, 1878, 1901, 2035, 2090, 2118, 2130, 2135, 2148, 2182, 2266, 2293, 2338, 2387, 2447, 2454, 2462, 2582, 2597, 2654, 2896, 2939, 3030, 3060, 3062, 3073, 3132, 3365, 3422, 3534, 3558, 3626, 3846, 3941, 4163, 4201, 4224, 4284, 4497, 4500, 4699, 4783, 4814, 4860, 5888, 5937, 6505, 6558, 6571, 6576, 6625, 7574, 8092, 8095, 8279, 8316, 8408, 8504, 8527, 9009, 9015, 9638, 9642, 9664, 9669, 9679, 9729]\n",
            "92 [193, 359, 449, 582, 593, 625, 646, 659, 674, 882, 1045, 1232, 1260, 1299, 1378, 1393, 1508, 1621, 1681, 1737, 1790, 1901, 1911, 2035, 2040, 2118, 2130, 2189, 2237, 2293, 2380, 2406, 2414, 2462, 2488, 2582, 2597, 2654, 2760, 2927, 3005, 3060, 3073, 3225, 3384, 3475, 3534, 3558, 3762, 3821, 3850, 3869, 3946, 3985, 4163, 4176, 4284, 4369, 4443, 4497, 4500, 4571, 4740, 4761, 4823, 4990, 5165, 5937, 5955, 6554, 6571, 6576, 6597, 6625, 6651, 6783, 6847, 7216, 7441, 8275, 8279, 8334, 8408, 9009, 9530, 9642, 9664, 9692, 9700, 9729, 9749, 9754]\n",
            "70 [359, 582, 625, 659, 674, 716, 726, 1039, 1226, 1232, 1299, 1393, 1508, 1737, 1790, 1847, 1878, 1901, 2035, 2040, 2118, 2130, 2135, 2293, 2414, 2454, 2462, 2488, 2597, 2654, 2823, 2939, 3030, 3073, 3225, 3365, 3384, 3422, 3534, 3558, 3749, 3762, 3821, 3846, 3869, 3906, 4497, 4547, 4699, 4761, 4814, 4823, 5265, 5937, 5955, 5972, 6558, 6571, 6576, 6625, 6847, 7441, 8279, 8408, 9009, 9642, 9664, 9679, 9729, 9754]\n",
            "101 [184, 247, 435, 447, 449, 582, 583, 659, 674, 740, 938, 947, 1014, 1039, 1050, 1226, 1232, 1299, 1364, 1393, 1527, 1621, 1681, 1737, 1754, 1782, 1790, 1878, 1901, 2035, 2040, 2118, 2130, 2135, 2148, 2182, 2266, 2293, 2447, 2462, 2488, 2582, 2597, 2654, 2927, 2939, 3073, 3132, 3225, 3288, 3422, 3475, 3534, 3558, 3726, 3762, 3767, 3821, 3846, 3906, 4007, 4065, 4163, 4176, 4201, 4224, 4497, 4699, 4740, 4761, 4783, 4823, 4860, 4879, 5888, 5937, 5972, 6554, 6555, 6558, 6559, 6571, 6576, 6578, 6597, 6625, 8095, 8279, 8316, 8408, 8527, 9009, 9015, 9019, 9642, 9664, 9679, 9698, 9729, 9749, 9792]\n"
          ]
        }
      ],
      "source": [
        "# imports ---------------------------------------------------------------------#\n",
        "import sys\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "import argparse\n",
        "import numpy as np \n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "\n",
        "def run(p_seed=0, p_kernel_size=5, p_logdir=\"temp\"):\n",
        "\n",
        "    # enable GPU usage ------------------------------------------------------------#\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    if use_cuda == False:\n",
        "        print(\"WARNING: CPU will be used for training.\")\n",
        "        exit(0)\n",
        "\n",
        "    # data loader -----------------------------------------------------------------#\n",
        "    test_dataset = MnistDataset(training=False, transform=None)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "    # model selection -------------------------------------------------------------#\n",
        "    if(p_kernel_size == 3):\n",
        "        model1 = ModelM3().to(device)\n",
        "    elif(p_kernel_size == 5):\n",
        "        model1 = ModelM5().to(device)\n",
        "    elif(p_kernel_size == 7):\n",
        "        model1 = ModelM7().to(device)\n",
        "\n",
        "    model1.load_state_dict(torch.load(\"/content/drive/MyDrive/UAS ML/1 DIGIT RECOGNITION/MnistSimpleCNN-master/logs/%s/model%03d.pth\"%(p_logdir,p_seed)))\n",
        "\n",
        "    model1.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    wrong_images = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model1(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            wrong_images.extend(np.nonzero(~pred.eq(target.view_as(pred)).cpu().numpy())[0]+(100*batch_idx))\n",
        "\n",
        "    np.savetxt(\"/content/drive/MyDrive/UAS ML/1 DIGIT RECOGNITION/MnistSimpleCNN-master/logs/%s/wrong%03d.txt\"%(p_logdir,p_seed), wrong_images, fmt=\"%d\")\n",
        "    print(len(wrong_images), wrong_images)\n",
        "\n",
        "p_seed = int(input (\"Seeds: \")) # input seeds value\n",
        "p_trials = int(input (\"Trials: \")) #input trial value\n",
        "p_kernel_size = int (input (\"Kernel size: \")) #input size kernel\n",
        "p_logdir = input (\"Logdir: \") #input model\n",
        "\n",
        "for x in range (p_trials):\n",
        "  run(p_seed + x, p_kernel_size, p_logdir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tetUfUZYci5p"
      },
      "source": [
        "homo ensamble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ejNtZ8hckC9",
        "outputId": "6d4781a2-5013-45f0-bd46-391510d2d3d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kernel size: 5\n",
            "   1   76   72   60   61   61\n",
            "   2   76   72   80   65   61\n",
            "   3   76   72   82   62   61\n",
            "   4   76   72   69   67   61\n",
            "   5   76   72   87   64   61\n",
            "   6   76   72   92   65   61\n",
            "   7   76   72   70   64   61\n",
            "   8   76   72  101   74   61\n",
            "   9   76   60   80   62   61\n",
            "  10   76   60   82   65   61\n",
            "  11   76   60   69   64   61\n",
            "  12   76   60   87   63   61\n",
            "  13   76   60   92   64   61\n",
            "  14   76   60   70   61   61\n",
            "  15   76   60  101   68   61\n",
            "  16   76   80   82   68   61\n",
            "  17   76   80   69   61   61\n",
            "  18   76   80   87   70   61\n",
            "  19   76   80   92   66   61\n",
            "  20   76   80   70   63   61\n",
            "  21   76   80  101   79   61\n",
            "  22   76   82   69   69   61\n",
            "  23   76   82   87   68   61\n",
            "  24   76   82   92   71   61\n",
            "  25   76   82   70   62   61\n",
            "  26   76   82  101   75   61\n",
            "  27   76   69   87   71   61\n",
            "  28   76   69   92   65   61\n",
            "  29   76   69   70   64   61\n",
            "  30   76   69  101   72   61\n",
            "  31   76   87   92   73   61\n",
            "  32   76   87   70   63   61\n",
            "  33   76   87  101   80   61\n",
            "  34   76   92   70   64   61\n",
            "  35   76   92  101   77   61\n",
            "  36   76   70  101   74   61\n",
            "  37   72   60   80   60   60\n",
            "  38   72   60   82   60   60\n",
            "  39   72   60   69   62   60\n",
            "  40   72   60   87   64   60\n",
            "  41   72   60   92   58   58\n",
            "  42   72   60   70   60   58\n",
            "  43   72   60  101   65   58\n",
            "  44   72   80   82   63   58\n",
            "  45   72   80   69   55   55\n",
            "  46   72   80   87   67   55\n",
            "  47   72   80   92   62   55\n",
            "  48   72   80   70   62   55\n",
            "  49   72   80  101   76   55\n",
            "  50   72   82   69   66   55\n",
            "  51   72   82   87   64   55\n",
            "  52   72   82   92   72   55\n",
            "  53   72   82   70   66   55\n",
            "  54   72   82  101   71   55\n",
            "  55   72   69   87   64   55\n",
            "  56   72   69   92   63   55\n",
            "  57   72   69   70   63   55\n",
            "  58   72   69  101   69   55\n",
            "  59   72   87   92   66   55\n",
            "  60   72   87   70   63   55\n",
            "  61   72   87  101   74   55\n",
            "  62   72   92   70   65   55\n",
            "  63   72   92  101   74   55\n",
            "  64   72   70  101   72   55\n",
            "  65   60   80   82   59   55\n",
            "  66   60   80   69   55   55\n",
            "  67   60   80   87   63   55\n",
            "  68   60   80   92   58   55\n",
            "  69   60   80   70   60   55\n",
            "  70   60   80  101   73   55\n",
            "  71   60   82   69   62   55\n",
            "  72   60   82   87   64   55\n",
            "  73   60   82   92   70   55\n",
            "  74   60   82   70   60   55\n",
            "  75   60   82  101   66   55\n",
            "  76   60   69   87   62   55\n",
            "  77   60   69   92   61   55\n",
            "  78   60   69   70   59   55\n",
            "  79   60   69  101   66   55\n",
            "  80   60   87   92   66   55\n",
            "  81   60   87   70   63   55\n",
            "  82   60   87  101   75   55\n",
            "  83   60   92   70   61   55\n",
            "  84   60   92  101   73   55\n",
            "  85   60   70  101   69   55\n",
            "  86   80   82   69   60   55\n",
            "  87   80   82   87   72   55\n",
            "  88   80   82   92   63   55\n",
            "  89   80   82   70   59   55\n",
            "  90   80   82  101   80   55\n",
            "  91   80   69   87   68   55\n",
            "  92   80   69   92   62   55\n",
            "  93   80   69   70   56   55\n",
            "  94   80   69  101   74   55\n",
            "  95   80   87   92   67   55\n",
            "  96   80   87   70   70   55\n",
            "  97   80   87  101   75   55\n",
            "  98   80   92   70   61   55\n",
            "  99   80   92  101   80   55\n",
            " 100   80   70  101   76   55\n",
            " 101   82   69   87   66   55\n",
            " 102   82   69   92   63   55\n",
            " 103   82   69   70   63   55\n",
            " 104   82   69  101   74   55\n",
            " 105   82   87   92   74   55\n",
            " 106   82   87   70   61   55\n",
            " 107   82   87  101   81   55\n",
            " 108   82   92   70   75   55\n",
            " 109   82   92  101   75   55\n",
            " 110   82   70  101   73   55\n",
            " 111   69   87   92   65   55\n",
            " 112   69   87   70   62   55\n",
            " 113   69   87  101   79   55\n",
            " 114   69   92   70   63   55\n",
            " 115   69   92  101   78   55\n",
            " 116   69   70  101   72   55\n",
            " 117   87   92   70   68   55\n",
            " 118   87   92  101   84   55\n",
            " 119   87   70  101   75   55\n",
            " 120   92   70  101   71   55\n"
          ]
        }
      ],
      "source": [
        "import numpy as np \n",
        "\n",
        "cnt = 1\n",
        "best = 10000\n",
        "curr = 10000\n",
        "\n",
        "p_kernel_size = int (input (\"Kernel size: \")) #input size kernel\n",
        "KERNEL_SIZE = p_kernel_size\n",
        "\n",
        "for i in range(10):\n",
        "    for j in range(i+1,10):\n",
        "        for k in range(j+1,10):\n",
        "            w1 = np.loadtxt(\"/content/drive/MyDrive/UAS ML/1 DIGIT RECOGNITION/MnistSimpleCNN-master/logs/modelM%d/wrong%03d.txt\"%(KERNEL_SIZE, i)).astype(np.int)\n",
        "            w2 = np.loadtxt(\"/content/drive/MyDrive/UAS ML/1 DIGIT RECOGNITION/MnistSimpleCNN-master/logs/modelM%d/wrong%03d.txt\"%(KERNEL_SIZE, j)).astype(np.int)\n",
        "            w3 = np.loadtxt(\"/content/drive/MyDrive/UAS ML/1 DIGIT RECOGNITION/MnistSimpleCNN-master/logs/modelM%d/wrong%03d.txt\"%(KERNEL_SIZE, k)).astype(np.int)\n",
        "\n",
        "            board = np.zeros((10000))\n",
        "            board[w1] += 1\n",
        "            board[w2] += 1\n",
        "            board[w3] += 1\n",
        "            board = board // 2\n",
        "            curr = np.sum(board)\n",
        "            if curr < best:\n",
        "                best = curr\n",
        "            print(\"%4d %4d %4d %4d %4d %4d\"%(cnt, len(w1), len(w2), len(w3), curr, best))\n",
        "            cnt += 1\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPgX9FqJi22t8RoBdetLc5d",
      "include_colab_link": true,
      "mount_file_id": "1XFlRGUeRlz6Nh39gDMJTEO3K0Gt0UnrU",
      "name": "1 UAS DIGIT RECOGNITION.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
