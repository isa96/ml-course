{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJwp-7LvK0sX"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a1w_0rSJKtJt",
        "outputId": "edf230e0-0bd8-4adc-bf86-6b7dbee27b90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting d2l==0.17.2\n",
            "  Downloading d2l-0.17.2-py3-none-any.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 126 kB/s \n",
            "\u001b[?25hCollecting numpy==1.18.5\n",
            "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting requests==2.25.1\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.7/dist-packages (from d2l==0.17.2) (1.0.0)\n",
            "Collecting matplotlib==3.3.3\n",
            "  Downloading matplotlib-3.3.3-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6 MB 58.4 MB/s \n",
            "\u001b[?25hCollecting pandas==1.2.2\n",
            "  Downloading pandas-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 43.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l==0.17.2) (4.10.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l==0.17.2) (5.2.2)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l==0.17.2) (7.6.5)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l==0.17.2) (5.3.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l==0.17.2) (5.2.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l==0.17.2) (5.6.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l==0.17.2) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l==0.17.2) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l==0.17.2) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l==0.17.2) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l==0.17.2) (1.3.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.2->d2l==0.17.2) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l==0.17.2) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l==0.17.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l==0.17.2) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l==0.17.2) (3.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.3.3->d2l==0.17.2) (1.15.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l==0.17.2) (5.3.5)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l==0.17.2) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l==0.17.2) (5.1.1)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l==0.17.2) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (0.2.5)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==0.17.2) (5.1.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==0.17.2) (3.5.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==0.17.2) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==0.17.2) (1.0.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (4.9.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (0.18.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (3.10.0.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (5.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (4.10.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (3.7.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l==0.17.2) (0.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l==0.17.2) (2.11.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l==0.17.2) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter==1.0.0->d2l==0.17.2) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter==1.0.0->d2l==0.17.2) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter==1.0.0->d2l==0.17.2) (2.0.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l==0.17.2) (0.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l==0.17.2) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l==0.17.2) (0.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l==0.17.2) (4.1.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l==0.17.2) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l==0.17.2) (1.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l==0.17.2) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l==0.17.2) (21.3)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter==1.0.0->d2l==0.17.2) (2.0.0)\n",
            "Installing collected packages: numpy, requests, pandas, matplotlib, d2l\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.25.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed d2l-0.17.2 matplotlib-3.3.3 numpy-1.18.5 pandas-1.2.2 requests-2.25.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install d2l==0.17.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYXo5OKLK-23"
      },
      "source": [
        "In this section, we will show you how to implement the linear regression model concisely by using high-level APIs of deep learning frameworks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeudaIbZLE66"
      },
      "source": [
        "##3.3.1. Generating the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GZeVl3VcLBbA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from d2l import tensorflow as d2l\n",
        "\n",
        "true_w = tf.constant([2, -3.4])\n",
        "true_b = 4.2\n",
        "features, labels = d2l.synthetic_data(true_w, true_b, 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcJtTly7LIWm"
      },
      "source": [
        "##3.3.2. Reading the Dataset\n",
        "\n",
        "Rather than rolling our own iterator, we can call upon the existing API in a framework to read data. We pass in features and labels as arguments and specify batch_size when instantiating a data iterator object. Besides, the boolean value is_train indicates whether or not we want the data iterator object to shuffle the data on each epoch (pass through the dataset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3OFL7Rh9LZTu"
      },
      "outputs": [],
      "source": [
        "def load_array(data_arrays, batch_size, is_train=True):\n",
        "    \"\"\"Construct a TensorFlow data iterator.\"\"\"\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(data_arrays)\n",
        "    if is_train:\n",
        "        dataset = dataset.shuffle(buffer_size=1000)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset\n",
        "\n",
        "batch_size = 10\n",
        "data_iter = load_array((features, labels), batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHKoMDPfLp18"
      },
      "source": [
        "Now we can use data_iter. To verify that it is working, we can read and print the first minibatch of examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gdhqFTaL8DW",
        "outputId": "72c20edc-f13e-4786-eb36-11c581da5de4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
              " array([[-0.26172063,  0.38331038],\n",
              "        [-1.1276855 , -1.6509379 ],\n",
              "        [ 0.9434952 ,  0.90271693],\n",
              "        [ 0.62092966,  1.8308698 ],\n",
              "        [ 1.1200039 , -0.5776032 ],\n",
              "        [ 0.9453936 , -0.16542035],\n",
              "        [ 1.5894574 ,  0.67671317],\n",
              "        [-0.48715246, -0.36461625],\n",
              "        [-0.87483805,  0.87743634],\n",
              "        [ 0.43445507, -1.0172988 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
              " array([[ 2.3603122],\n",
              "        [ 7.5584755],\n",
              "        [ 3.0224087],\n",
              "        [-0.781395 ],\n",
              "        [ 8.392234 ],\n",
              "        [ 6.6481028],\n",
              "        [ 5.0897408],\n",
              "        [ 4.480731 ],\n",
              "        [-0.5316329],\n",
              "        [ 8.524435 ]], dtype=float32)>)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(data_iter))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3uhq3ulL_dW"
      },
      "source": [
        "##3.3.3. Defining the Model\n",
        "\n",
        "For standard operations, we can use a framework’s predefined layers, which allow us to focus especially on the layers used to construct the model rather than having to focus on the implementation.\n",
        "\n",
        "Recall the architecture of a single-layer network. The layer is said to be fully-connected because each of its inputs is connected to each of its outputs by means of a matrix-vector multiplication."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTIYSh5IM-Q8"
      },
      "source": [
        "In Keras, the fully-connected layer is defined in the Dense class. Since we only want to generate a single scalar output, we set that number to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NovWty0iNTyI"
      },
      "outputs": [],
      "source": [
        "# `keras` is the high-level API for TensorFlow\n",
        "net = tf.keras.Sequential()\n",
        "net.add(tf.keras.layers.Dense(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL4hWhVwNVoj"
      },
      "source": [
        "##3.3.4. Initializing Model Parameters\n",
        "\n",
        "Before using net, we need to initialize the model parameters, such as the weights and bias in the linear regression model.\n",
        "\n",
        "Here we specify that each weight parameter should be randomly sampled from a normal distribution with mean 0 and standard deviation 0.01. The bias parameter will be initialized to zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FiBkqKvNtBT"
      },
      "source": [
        "The easiest way to specify the initialization method in Keras is when creating the layer by specifying kernel_initializer. Here we recreate net again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7Clzhy1jNsq-"
      },
      "outputs": [],
      "source": [
        "initializer = tf.initializers.RandomNormal(stddev=0.01)\n",
        "net = tf.keras.Sequential()\n",
        "net.add(tf.keras.layers.Dense(1, kernel_initializer=initializer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8fclejHN6hm"
      },
      "source": [
        "We are initializing parameters for a network even though Keras does not yet know how many dimensions the input will have! It might be 2 as in our example or it might be 2000. Keras lets us get away with this because behind the scenes, the initialization is actually deferred. The real initialization will take place only when we for the first time attempt to pass data through the network. Just be careful to remember that since the parameters have not been initialized yet, we cannot access or manipulate them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3LcHCILOF_1"
      },
      "source": [
        "##3.3.5. Defining the Loss Function\n",
        "\n",
        "The MeanSquaredError class computes the mean squared error. By default it returns the average loss over examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MkobhfW5OSB8"
      },
      "outputs": [],
      "source": [
        "loss = tf.keras.losses.MeanSquaredError()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3Pp0cn-OTdf"
      },
      "source": [
        "##3.3.6. Defining the Optimization Algorithm\n",
        "\n",
        "Minibatch stochastic gradient descent is a standard tool for optimizing neural networks and thus Keras supports it alongside a number of variations on this algorithm in the optimizers module. Minibatch stochastic gradient descent just requires that we set the value learning_rate, which is set to 0.03 here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cYSsTw95OgK8"
      },
      "outputs": [],
      "source": [
        "trainer = tf.keras.optimizers.SGD(learning_rate=0.03)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TL1Rvy8Oijf"
      },
      "source": [
        "##3.3.7. Training\n",
        "\n",
        "Once we start working with much more complex models, advantages of high-level APIs will grow considerably.\n",
        "\n",
        "To refresh your memory: for some number of epochs, we will make a complete pass over the dataset (train_data), iteratively grabbing one minibatch of inputs and the corresponding ground-truth labels. For each minibatch, we go through the following ritual:\n",
        "\n",
        "Generate predictions by calling net(X) and calculate the loss l (the forward propagation).\n",
        "\n",
        "Calculate gradients by running the backpropagation.\n",
        "\n",
        "Update the model parameters by invoking our optimizer.\n",
        "\n",
        "For good measure, we compute the loss after each epoch and print it to monitor progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiLroKlaO_8H",
        "outputId": "1f7ae898-d968-4124-ee04-2c56d5e016d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1, loss 0.000261\n",
            "epoch 2, loss 0.000099\n",
            "epoch 3, loss 0.000098\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    for X, y in data_iter:\n",
        "        with tf.GradientTape() as tape:\n",
        "            l = loss(net(X, training=True), y)\n",
        "        grads = tape.gradient(l, net.trainable_variables)\n",
        "        trainer.apply_gradients(zip(grads, net.trainable_variables))\n",
        "    l = loss(net(features), labels)\n",
        "    print(f'epoch {epoch + 1}, loss {l:f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1wDyXZOPJ2H"
      },
      "source": [
        "Below, we compare the model parameters learned by training on finite data and the actual parameters that generated our dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KXy7e2pPLxC",
        "outputId": "1b62d405-053e-407b-a310-41375670286d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "error in estimating w tf.Tensor([-0.00031352  0.00027657], shape=(2,), dtype=float32)\n",
            "error in estimating b [9.8228455e-05]\n"
          ]
        }
      ],
      "source": [
        "w = net.get_weights()[0]\n",
        "print('error in estimating w', true_w - tf.reshape(w, true_w.shape))\n",
        "b = net.get_weights()[1]\n",
        "print('error in estimating b', true_b - b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95oFDF64PPOg"
      },
      "source": [
        "##3.3.8. Summary\n",
        "\n",
        "* Using TensorFlow’s high-level APIs, we can implement models much more concisely.\n",
        "\n",
        "* In TensorFlow, the data module provides tools for data processing, the keras module defines a large number of neural network layers and common loss functions.\n",
        "\n",
        "* TensorFlow’s module initializers provides various methods for model parameter initialization.\n",
        "\n",
        "* Dimensionality and storage are automatically inferred (but be careful not to attempt to access parameters before they have been initialized)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOCM41cr4lO+xk9QeLtE5lH",
      "include_colab_link": true,
      "name": "3.3. Concise Implementation of Linear Regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
